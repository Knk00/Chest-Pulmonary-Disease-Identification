{"cells":[{"metadata":{},"cell_type":"markdown","source":"Questions to ask:\n - What is the age distribution and is it normal?\n - Is the variables correlated?\n - Can the images of the smoker and non-smoker be easily distinguished?","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport re\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom nltk.tokenize import RegexpTokenizer\nfrom wordcloud import WordCloud\nfrom colorama import Fore, Back, Style #color style\nfrom tqdm.notebook import tqdm\nfrom plotly.subplots import make_subplots\nimport random\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Machine Learning and Deep Learning Modules\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nimport category_encoders as ce\n\nfrom sklearn.linear_model import Ridge, ElasticNet\nfrom functools import partial\nimport scipy as sp\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\n\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pydicom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install chart_studio\nimport plotly.express as px\nimport chart_studio.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport cufflinks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistical Packages\nfrom scipy.stats import shapiro\nfrom scipy import stats \nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nimport pickle\nimport gc\nimport pydicom\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!conda install -y gdcm -c conda-forge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a random seed\ndef all_seed(seed=857):\n    random.seed(seed)\n    os.environ['seed_rand'] = str(seed)\n    np.random.seed(seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_DICT = './'\n\nID = 'Patient_Week'\nTARGET = 'FVC'\nSEED = 909 \nall_seed(seed=SEED)\n\nN_FOLD = 9","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading the Dataset\ntrain_fibro = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\ntest_fibro = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First rows of train dataset\ntrain_fibro.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First rows of test dataset\ntest_fibro.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the smoking status to sex\ntrain_fibro.groupby(['SmokingStatus']).count()['Sex'].to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age status to sex\ntrain_fibro.groupby(['Age']).count()['Sex'].to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age Distribution\nplt.hist(train_fibro['Age'], color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the Deviation Column\ntrain_fibro[\"Deviation\"] = train_fibro['FVC']/train_fibro['Percent']\ntest_fibro['Deviation'] = test_fibro['FVC']/test_fibro['Percent']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the train_fibro dataset again\ntrain_fibro.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the test_fibro dataset again\ntest_fibro.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary statistics for train dataset\ntrain_fibro.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test dataset summary dataset\ntest_fibro.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of train_fibro deviation\nplt.hist(train_fibro['Deviation'], color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at Missing Values\ntrain_fibro.isnull().sum() #Training dataset\nsns.heatmap(train_fibro.isnull(), cbar='Magma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fibro.isnull().sum() #testing dataset\n\nsns.heatmap(test_fibro.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This dataset has no missing values, let's march on to the analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Correlation\ntrain_fibro.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Correlation Matrix\ncorr_matrix = train_fibro.corr() \nf, ax = plt.subplots(figsize =(15, 13)) \nsns.heatmap(corr_matrix, ax = ax, cmap = 'viridis', linewidths = 0.5) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Correlation\ntest_fibro.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Correlation Heatmap\ncorr_matrix = test_fibro.corr() \nf, ax = plt.subplots(figsize =(15, 13)) \nsns.heatmap(corr_matrix, ax = ax, cmap = 'magma', linewidths = 0.5) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test dataset has a higher correlation between the percent vs. weeks. The same result is happening with the train dataset as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking for unique values\ntrain_patient_id = set(train_fibro['Patient'].unique())\ntest_patient_id = set(test_fibro['Patient'].unique())\n\ntrain_patient_id.intersection(test_patient_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the counts for the training dataset\nprint(train_fibro['Patient'].count(),train_fibro['Patient'].value_counts().shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing dataset counts\nprint(test_fibro['Patient'].count(),test_fibro['Patient'].value_counts().shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_patient_ids = set(train_fibro['Patient'].unique())\ntest_patient_ids = set(test_fibro['Patient'].unique())\n\ntrain_patient_ids.intersection(test_patient_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the column names on the training dataset\ntrain_fibro_col = train_fibro.keys()\ntrain_fibro_col = list(train_fibro_col)\nprint(train_fibro_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing dataset for the column names\ntest_fibro_col = test_fibro.keys()\ntest_fibro_col = list(test_fibro_col)\nprint(test_fibro_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the Unique Patient counts\ntrain_fibro['Patient'].value_counts().max()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing version of it\ntest_fibro['Patient'].value_counts().max()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the 95% of confidence interval of the values for the patient\nprint(np.quantile(train_fibro['Patient'].value_counts(), 0.95))\nprint(np.quantile(test_fibro['Patient'].value_counts(), 0.95))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age differences\nnp.quantile(train_fibro['Age'].value_counts(), 0.75) - np.quantile(test_fibro['Age'].value_counts(), 0.25)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the value counts for the differences\nnp.quantile(train_fibro['Patient'].value_counts(), 0.75) - np.quantile(test_fibro['Patient'].value_counts(), 0.25)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the PVC Variable at 5% significance\nstat, p_value = shapiro(train_fibro['FVC'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p_value))\n# interpret\nalpha = 0.05\nif p_value > alpha:\n    print('Sample resembles to Gaussian (fail to reject H0)')\nelse:\n    print('reject H0')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Lambda Values\n\n_, lambda_fit = stats.boxcox(train_fibro['FVC']) \nprint(\"Lambda Values: \", lambda_fit)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box-Cox Functions\ndef bctransform(x, lamb):\n    part1 = x**lamb\n    part2 = part1-1\n    result = part2/lamb\n    return result\n\ndef reversebct(x, lamb):\n    x = np.where(x<0,0,x)\n    part1 = x*lamb + 1\n    result = part1**(1/lamb)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse Box Cox Transform\ntrain_fitted = bctransform(train_fibro['FVC'], lamb=lambda_fit)\nplt.hist(reversebct(train_fitted, lamb=lambda_fit))\nplt.xlabel('FVC')\nplt.ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shapiro Test on Box Cox Reverse\nstat, p = shapiro(train_fitted)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Fail to reject H0')\nelse:\n    print('Reject H0')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting distributions of fitted data in the training dataset\nplt.hist(reversebct(train_fitted, lamb=lambda_fit))\nplt.xlabel('FVC')\nplt.ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot\ntrace0 = go.Box(y=train_fibro[\"Age\"],name=\"Age\")\ntrace1 = go.Box(y=train_fibro[\"Percent\"],name=\"Percent\")\n\n\ntracer = [trace0,  trace1]\niplot(tracer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the weeks distribution on the training dataset\ntrain_fibro['Weeks'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the weeks distribution on the test dataset\ntest_fibro['Weeks'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at how long the patient stays for lung treatment\nfibro_weeks = train_fibro.groupby(\"Patient\").agg({\"Weeks\":\"nunique\",\"Age\":\"nunique\"}).reset_index()\nfig, (ax1,ax2) = plt.subplots(1,2,figsize=(12,8))\nsns.countplot(fibro_weeks.Weeks,ax = ax1);\nsns.countplot(fibro_weeks.Age,ax =ax2);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Week 9 has the highest counts for the patient recordings in the lung treatments. Each of them has 1 year age of difference.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Weeks Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fibro['Weeks'].hist(color=\"orange\")\nplt.xlabel('Weeks') \nplt.ylabel('Count') \nplt.title('Training Set Weeks Distribution', \n          fontweight =\"bold\") \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age Distribution\ntrain_fibro_patients = train_fibro[[\"Patient\",\"Sex\",\"SmokingStatus\",\"Age\"]].drop_duplicates()\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 5),gridspec_kw={'width_ratios': [1,1,2]})\nsns.countplot(train_fibro_patients.Sex,ax = ax1);\nsns.countplot(train_fibro_patients.SmokingStatus,ax =ax2);\nsns.countplot(train_fibro_patients.Age,ax =ax3);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot of Weeks vs. Age\nfigure = px.scatter(train_fibro, x=\"Weeks\", y=\"Age\", color='Sex')\nfigure.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bootstrap Preparation\ntrain_fibro_boot_dev = np.array(train_fibro['Deviation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Bootstrap Model\ntrain_fibro_bootstrap = []\nfor i in range(10000):\n    np.random.seed(i)\n    train_fibro_bootstrap.append((resample(train_fibro_boot_dev)))\nprint(len(train_fibro_bootstrap))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating Bootstrap Means\nbootstrap_means = np.mean(train_fibro_bootstrap, axis=1)\nbootstrap_means","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of Bootstrap Means\nlower_bound = np.percentile(bootstrap_means, 2.5)\nupper_bound = np.percentile(bootstrap_means, 97.5)\n\nfig = plt.figure(figsize=(10,3))\nax = plt.hist(bootstrap_means, bins=30)\n\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.axvline(lower_bound, color='r')\nplt.axvline(upper_bound, color='r')\nplt.show()\n\nprint('Lower bound: {}'.format(lower_bound))\nprint('Upper bound: {}'.format(upper_bound))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing Fastai\n!pip install fastai2 -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the X-Ray Images\ntrain_image_data = \"../input/osic-pulmonary-fibrosis-progression/train\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking up DCM Files\nprint(Fore.GREEN + 'Train .dcm number of images:',Style.RESET_ALL, len(list(os.listdir('../input/osic-pulmonary-fibrosis-progression/train'))), '\\n' +\n      Fore.BLUE + 'Test .dcm number of images:',Style.RESET_ALL, len(list(os.listdir('../input/osic-pulmonary-fibrosis-progression/test'))), '\\n' +\n      '--------------------------------', '\\n' +\n      'There is the same number of images as in train/ test .csv datasets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pix_array(dataset, figsize=(10,8)):\n    plt.figure(figsize=figsize)\n    plt.grid(False)\n    plt.imshow(dataset.pix_array, cmap='gray') # cmap=plt.cm.bone (color))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Smoker\ndir_image = \"../input/osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430\"\nprint(\"total images for patient ID00007637202177411956430: \", len(os.listdir(dir_image)))\n\n# view first (columns*rows) images in order\nfig=plt.figure(figsize=(14, 14))\ncolumns = 5\nrows = 4\nimglist = os.listdir(dir_image)\nfor i in range(1, columns*rows +1):\n    filename = dir_image + \"/\" + str(i) + \".dcm\"\n    ds = pydicom.dcmread(filename)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(ds.pixel_array, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Patient ID00426637202313170790466 (Non-Smoker)\n\ndir_image = \"../input/osic-pulmonary-fibrosis-progression/test/ID00426637202313170790466\"\nprint(\"total images for patient ID00426637202313170790466: \", len(os.listdir(dir_image)))\n\n# view first (columns*rows) images in order\nfig=plt.figure(figsize=(14, 14))\ncolumns = 5\nrows = 4\nimglist = os.listdir(dir_image)\nfor i in range(1, columns*rows +1):\n    filename = dir_image + \"/\" + str(i) + \".dcm\"\n    ds = pydicom.dcmread(filename)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(ds.pixel_array, cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Creating the train inputs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\ntrain = pd.concat([train_fibro, test_fibro])\n\noutput = pd.DataFrame()\n\ngb = train_fibro.groupby('Patient') # Combines all col data by object name and return mean values respectively\n\n# tqdm => i love you so much in spanish, progress bar for running loops\n\ntk0 = tqdm(gb, total = len(gb))\n\nfor _, usr_df in tk0:\n    usr_output = pd.DataFrame()\n    for week, tmp in usr_df.groupby(\"Weeks\"):\n        rename_cols = {'Weeks': 'origin_week', 'FVC': 'origin_FVC', 'Age': 'origin_age'}\n        \n        tmp = tmp.rename(columns = rename_cols)\n        \n        drop_cols = ['Age', 'Sex', 'SmokingStatus', 'Percent'] \n        \n        _usr_output = usr_df.drop(columns=drop_cols).rename(columns={'Weeks': 'pred_week'}).merge(tmp, on='Patient')\n        \n        _usr_output['week_pass'] = _usr_output['pred_week'] - _usr_output['origin_week']\n        \n        # Concat the empty DF with edited DF\n        usr_output = pd.concat([usr_output, _usr_output])\n    output = pd.concat([output, usr_output])\n        \ntrain = output[output['week_pass']!=0].reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looking at the output","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Doing it for the test set\ntest = test_fibro.rename(columns={'Weeks': 'origin_week', 'FVC': 'origin_FVC', 'Age': 'origin_age'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission Set\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\n\nsample_submission_fibro = pd.read_csv(\"../input/osic-pulmonary-fibrosis-progression/sample_submission.csv\")\n\nsample_submission_fibro['Patient'] = sample_submission_fibro['Patient_Week'].apply(lambda x:x.split('_')[0])\n\n# In submisison file, format: ID_'week', using lambda to split the Week\nsample_submission_fibro['Patient'] = sample_submission_fibro['Patient_Week'].apply(lambda x:x.split('_')[0])\n\n# In submisison file, format: ID_'week', using lambda to split the Week\nsample_submission_fibro['pred_week'] = sample_submission_fibro['Patient_Week'].apply(lambda x:x.split('_')[1]).astype(int)\n\ntest = sample_submission_fibro.drop(columns = [\"FVC\", \"Confidence\"]).merge(test, on = 'Patient')\n\ntest['Week_passed'] = test['pred_week'] - test['origin_week']\n\ntest.set_index('Patient_Week', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the Folds\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\n\nfolds = train[['Patient', TARGET]].copy()\nfolds = train[['Patient', TARGET]].copy()\nFold = GroupKFold(n_splits=N_FOLD)\ngroups = folds['Patient'].values\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[TARGET], groups)):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the Model to Build\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\n\ndef singular_mod(clf, train_frame, test_frame, folds, features, target, fold_num=0):\n    tr_index = folds[folds.fold!=fold_num].index\n    valid_index = folds[folds.fold==fold_num].index\n    \n    y_tr = target.iloc[tr_index].values\n    X_tr = train_frame.iloc[tr_index][features].values\n    y_val = target.iloc[valid_index].values\n    X_val = train_frame.iloc[valid_index][features].values\n    \n    oof = np.zeros(len(train_frame))\n    predictions = np.zeros(len(test_frame))\n    clf.fit(X_tr, y_tr)\n    \n    oof[val_idx] = clf.predict(X_val)\n    predictions += clf.predict(test_frame[features])\n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Fold Model\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\n\ndef kf_mod(clf, train, test, folds, features, target, n_fold=9):\n    \n    # n_fold from 5 to 7\n    \n    oof = np.zeros(len(train))\n    predictions = np.zeros(len(test))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_ in range(n_fold):\n\n        _oof, _predictions = singular_mod(clf,train, test, folds, features, target, fold_num = fold_)\n\n        oof += _oof\n        predictions += _predictions/n_fold\n    \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting for FVC\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\ntarget = train[TARGET]\ntest[TARGET] = np.nan \n\n# features\ncat_features = ['Sex', 'SmokingStatus'] # Categorical Features\nnum_features = [c for c in test.columns if (test.dtypes[c] != 'object') & (c not in cat_features)] # Numerical Features\n\nfeatures = num_features + cat_features\ndrop_features = [TARGET, 'pred_week', 'Percent', 'origin_week']\nfeatures = [c for c in features if c not in drop_features]\n\nif cat_features:\n    ce_oe = ce.OrdinalEncoder(cols=cat_features, handle_unknown='impute')\n    ce_oe.fit(train)\n    train = ce_oe.transform(train)\n    test = ce_oe.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the score\n## https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n\nfor alpha1 in [0.4]:\n    for l1s in [0.75]:\n        \n        print(\" For alpha:\",alpha1,\"& l1_ratio:\",l1s)\n        clf = ElasticNet(alpha=alpha1, l1_ratio = l1s)\n        oof, predictions = kf_mod(clf, train, test, folds, features, target, n_fold=N_FOLD)\n\n        train['FVC_pred'] = oof\n        test['FVC_pred'] = predictions\n\n        # baseline score\n        train['Confidence'] = 100\n        train['sigma_clipped'] = train['Confidence'].apply(lambda x: max(x, 75))\n        train['diff'] = abs(train['FVC'] - train['FVC_pred'])\n        train['delta'] = train['diff'].apply(lambda x: min(x, 1000))\n        train['score'] = -math.sqrt(2)*train['delta']/train['sigma_clipped'] - np.log(math.sqrt(2)*train['sigma_clipped'])\n        score = train['score'].mean()\n        print(score)\n\n        def loss_func(weight, row):\n            confidence = weight\n            sigma_clipped = max(confidence, 70)\n            diff = abs(row['FVC'] - row['FVC_pred'])\n            delta = min(diff, 1000)\n            score = -math.sqrt(2)*delta/sigma_clipped - np.log(math.sqrt(2)*sigma_clipped)\n            return -score\n\n        results = []\n        tk0 = tqdm(train.iterrows(), total=len(train))\n        for _, row in tk0:\n            loss_partial = partial(loss_func, row=row)\n            weight = [100]\n            result = sp.optimize.minimize(loss_partial, weight, method='SLSQP')\n            x = result['x']\n            results.append(x[0])\n\n        # optimized score\n        train['Confidence'] = results\n        train['sigma_clipped'] = train['Confidence'].apply(lambda x: max(x, 75))\n        train['diff'] = abs(train['FVC'] - train['FVC_pred'])\n        train['delta'] = train['diff'].apply(lambda x: min(x, 1000))\n        train['score'] = -math.sqrt(2)*train['delta']/train['sigma_clipped'] - np.log(math.sqrt(2)*train['sigma_clipped'])\n        score = train['score'].mean()\n        print(score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References:\n- https://www.kaggle.com/piantic/osic-pulmonary-fibrosis-progression-basic-eda\n- https://www.kaggle.com/yeayates21/osic-image-data-prep-and-baseline-regression-model\n- https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n- https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\n- https://www.kaggle.com/jagadish13/osic-baseline-elasticnet-eda\n- https://www.raddq.com/dicom-processing-segmentation-visualization-in-python/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}